{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhura206/Forest-Fire-Detection/blob/main/wildfire_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7-iZPVsJxyfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7249e9b3-a46a-4d97-f42b-9694dc070a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/abdelghaniaaba/wildfire-prediction-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.45G/1.45G [00:17<00:00, 91.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/abdelghaniaaba/wildfire-prediction-dataset/versions/1\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/techsash/waste-classification-data?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 427M/427M [00:03<00:00, 135MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/techsash/waste-classification-data/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"abdelghaniaaba/wildfire-prediction-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"techsash/waste-classification-data\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pRP9NrPxykr4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #for data augumentation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog #provides a dialog box to select files.\n",
        "from PIL import Image, ImageTk #ImageTk - Converts images for display in Tkinter GUIs\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BDISersMzUA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b571233-22de-4d76-aa7c-743a8d1c5a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30250 images belonging to 2 classes.\n",
            "Found 6300 images belonging to 2 classes.\n",
            "Found 6300 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Set up directories\n",
        "train_dir = r\"/root/.cache/kagglehub/datasets/abdelghaniaaba/wildfire-prediction-dataset/versions/1/train\"\n",
        "valid_dir = r\"/root/.cache/kagglehub/datasets/abdelghaniaaba/wildfire-prediction-dataset/versions/1/valid\"\n",
        "test_dir = r\"/root/.cache/kagglehub/datasets/abdelghaniaaba/wildfire-prediction-dataset/versions/1/test\"\n",
        "\n",
        "# Set up ImageDataGenerators for loading images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load images from directories\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n",
        "valid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n",
        "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cyUhEjpJ8CfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb128cd-b234-4a17-86e8-9196a38454c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Building a simple CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification: wildfire or no wildfire\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YNgXHRXv9C9R"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqH89BSI9XLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267f268d-9bbf-4663-bba9-78ff8597e157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m393/946\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 112ms/step - accuracy: 0.8593 - loss: 0.3217"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, validation_data=valid_generator, epochs=1, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "model.save(\"ffd_model.h5\")"
      ],
      "metadata": {
        "id": "nIXq0WcCQBKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "Ri2TLaqke91s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "\n",
        "from PIL import Image, ImageTk\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "model = load_model(\"ffd_model.h5\")\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Function to load and predict an image\n",
        "def predict_image(img):\n",
        "  \"\"\"Predicts whether an image contains wildfire or not.\n",
        "\n",
        "  Args:\n",
        "    img: The input image.\n",
        "\n",
        "  Returns:\n",
        "    A string indicating the prediction (\"Wildfire\" or \"No Wildfire\").\n",
        "  \"\"\"\n",
        "  img = img.resize((64, 64))\n",
        "  img_array = np.array(img) / 255.0  # Rescale like during training\n",
        "  img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "  prediction = model.predict(img_array)[0][0]  # Extracts the scalar prediction value\n",
        "  result = \"Wildfire\" if prediction > 0.5 else \"No Wildfire\"\n",
        "  return result\n",
        "\n",
        "# Create a Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_image,\n",
        "    inputs=gr.Image(type=\"pil\"),  # Input type is PIL Image\n",
        "    outputs=\"text\",\n",
        "    title=\"Forest Fire Detection\",\n",
        "    description=\"Upload an image to predict whether it contains wildfire or not.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "nM-H67mdfJaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}